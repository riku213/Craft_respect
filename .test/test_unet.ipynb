{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1312834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from src.my_app import UNet, PreTrainDataset, create_optimized_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d89da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "jsonデータを読み込みました。\n",
      "Pre-computing ground truth data...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def crop_labels_to_match(labels_to_crop, target_tensor):\n",
    "    target_h, target_w = target_tensor.shape[2:]\n",
    "    source_h, source_w = labels_to_crop.shape[2:]\n",
    "    delta_h = (source_h - target_h) // 2\n",
    "    delta_w = (source_w - target_w) // 2\n",
    "    return labels_to_crop[:, :, delta_h:delta_h + target_h, delta_w:delta_w + target_w]\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resizeze((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# --- Dataset ---\n",
    "test_doc_id_list = ['100241706', '100249371', '100249376', '100249416', '100249476', '100249537', '200003076', '200003803', '200003967', '200004107']\n",
    "train_dataset = PreTrainDataset(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=False,\n",
    "    device=torch.device('cuda'),  # GPUを明示的に指定\n",
    "    precompute_gt=True,  # 事前計算を有効化\n",
    "    # num_workers=None\n",
    "    transform=transform  # 画像変換を追加\n",
    ")\n",
    "test_dataset = PreTrainDataset(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=True,\n",
    "    device=torch.device('cuda'),  # GPUを明示的に指定\n",
    "    precompute_gt=True,  # 事前計算を有効化\n",
    "    # num_workers=4\n",
    "    transform=transform  # 画像変換を追加\n",
    ")\n",
    "\n",
    "# 最適化されたDataLoaderの作成\n",
    "train_dl = create_optimized_dataloader(train_dataset, batch_size=1, num_workers=min(mp.cpu_count(), 4))\n",
    "test_dl = create_optimized_dataloader(test_dataset, batch_size=1, num_workers=min(mp.cpu_count(), 4))\n",
    "\n",
    "# --- モデル、損失関数、最適化手法の定義 ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(3, 4).to(device)\n",
    "criterion = nn.MSELoss() # 回帰問題なのでMSE損失を使用\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- 学習ループの拡張 ---\n",
    "\n",
    "num_epochs = 100 # エポック数を定義\n",
    "\n",
    "# 損失の履歴を保存するリストを初期化\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "print(\"学習を開始します...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'start epcoch')\n",
    "    # --- 訓練フェーズ ---\n",
    "    model.train() # モデルを訓練モードに設定\n",
    "    train_loss_total = 0\n",
    "    \n",
    "    # tqdmでプログレスバーを表示\n",
    "    train_bar = tqdm(train_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "    for imgs, masks in train_bar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        \n",
    "        preds = model(imgs)\n",
    "        cropped_masks = crop_labels_to_match(masks, preds)\n",
    "\n",
    "        loss = criterion(preds, cropped_masks)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_total += loss.item()\n",
    "        # プログレスバーに現在のロスを表示\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss_total / len(train_dl)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "\n",
    "    # --- 評価フェーズ ---\n",
    "    model.eval() # モデルを評価モードに設定\n",
    "    test_loss_total = 0\n",
    "    \n",
    "    # 勾配計算を無効化して、メモリ効率を良くする\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Test]\")\n",
    "        for imgs, masks in test_bar:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            preds = model(imgs)\n",
    "            cropped_masks = crop_labels_to_match(masks, preds)\n",
    "            \n",
    "            loss = criterion(preds, cropped_masks)\n",
    "            test_loss_total += loss.item()\n",
    "            test_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_test_loss = test_loss_total / len(test_dl)\n",
    "    test_loss_history.append(avg_test_loss)\n",
    "    \n",
    "    # 各エポックの最後に訓練ロスとテストロスを表示\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "print(\"学習が完了しました。\")\n",
    "\n",
    "# --- 損失の推移をグラフで表示 ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(test_loss_history, label=\"Test Loss\")\n",
    "plt.title(\"Loss Trend\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ec8719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kotat\\MyPrograms\\MyKuzushiji\\Craft_respect\\.test\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257d655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kuzushiji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
