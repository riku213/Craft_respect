{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional\n",
    "from PIL import Image\n",
    "\n",
    "class PreTrainDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 test_doc_id_list,\n",
    "                 test_mode=False,\n",
    "                 # input_path='../kuzushiji_recognition/synthetic_images/input_images/',\n",
    "                 input_path='../kuzushiji_recognition/synthetic_images/tmp_entire_data/',\n",
    "                 json_path='../kuzushiji_recognition/synthetic_images/gt_json.json',\n",
    "                 transform=None,\n",
    "                 target_width=300):  # デフォルトの横幅を300に設定\n",
    "        super().__init__()\n",
    "        self.test_doc_id_list = test_doc_id_list\n",
    "        self.input_path = input_path\n",
    "        self.transform = transform\n",
    "        self.target_width = target_width\n",
    "        \n",
    "        # 画像のIDをリストにして保管。\n",
    "        self.input_imageID_list = []\n",
    "        for file_name in os.listdir(self.input_path):\n",
    "            file_path = os.path.join(self.input_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                # test_modeに応じて、テスト用データと学習用データを切り分ける\n",
    "                # XOR (^) を利用:\n",
    "                # - test_mode=False (学習時): doc_idがtest_listにない(False) -> 全体はFalse -> 読み込む\n",
    "                # - test_mode=True (テスト時): doc_idがtest_listにある(True) -> 全体はFalse -> 読み込む\n",
    "                if not (file_name.split('_sep_')[0] in self.test_doc_id_list) ^ test_mode:\n",
    "                    self.input_imageID_list.append(file_name.split('.')[0])\n",
    "        \n",
    "        # アノテーションデータを保持するjsonファイルをロード\n",
    "        self.gt_json = self.load_GT_json(json_path)\n",
    "\n",
    "        # 入力画像に対応するアノテーションデータが存在するか確認。(コメントアウト)\n",
    "        # for i in range(len(self.input_imageID_list)-1, -1,-1):\n",
    "        #     if not self.input_imageID_list[i] in self.gt_json:\n",
    "        #         del self.input_imageID_list[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_imageID_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.input_imageID_list[index]\n",
    "        image = Image.open(self.input_path + image_id + '.jpg')\n",
    "        \n",
    "        # 1. 元の画像のサイズを取得\n",
    "        original_w, original_h = image.size\n",
    "        \n",
    "        # 2. アスペクト比を保持したまま、横幅を指定サイズにリサイズ\n",
    "        aspect_ratio = original_h / original_w\n",
    "        new_w = self.target_width\n",
    "        new_h = int(self.target_width * aspect_ratio)\n",
    "        new_size = (new_h, new_w)  # functional.resizeはH,Wの順で指定\n",
    "        \n",
    "        # 3. 画像をリサイズ\n",
    "        image = functional.resize(image, new_size, interpolation=functional.InterpolationMode.BILINEAR)\n",
    "        \n",
    "        # 4. リサイズ後のサイズで正解マップを生成\n",
    "        tensor_gt = self.return_tensor_gt(\n",
    "            gt_info_dic=self.gt_json['files'][image_id],\n",
    "            image=image,\n",
    "            original_size=(original_w, original_h)\n",
    "        )\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, tensor_gt\n",
    "\n",
    "    def load_GT_json(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(\"json データを読み込みました。\")\n",
    "        return data\n",
    "\n",
    "    def return_ground_truth_canvas(self, image):\n",
    "        w, h = image.size\n",
    "        main_region = np.zeros((h, w), dtype=np.float64)\n",
    "        main_affinity = np.zeros((h, w), dtype=np.float64)\n",
    "        furi_region = np.zeros((h, w), dtype=np.float64)\n",
    "        furi_affinity = np.zeros((h, w), dtype=np.float64)\n",
    "        return main_region, main_affinity, furi_region, furi_affinity\n",
    "\n",
    "    def add_perspective_gaussian_to_canvas(self, canvas, points, amplitude=1.0):\n",
    "        # 領域の4点を取得\n",
    "        src_points = np.array(points, dtype=np.float32)\n",
    "\n",
    "        # ガウス分布を生成するための仮想的な正方形領域を定義\n",
    "        width = int(max(np.linalg.norm(src_points[0] - src_points[1]), np.linalg.norm(src_points[2] - src_points[3])))\n",
    "        height = int(max(np.linalg.norm(src_points[0] - src_points[3]), np.linalg.norm(src_points[1] - src_points[2])))\n",
    "        \n",
    "        # 最小サイズを保証（1ピクセル未満にならないようにする）\n",
    "        width = max(width, 1)\n",
    "        height = max(height, 1)\n",
    "        \n",
    "        # ガウス分布のサイズを調整（小さすぎる場合は大きくする）\n",
    "        min_gaussian_size = 5\n",
    "        if width < min_gaussian_size or height < min_gaussian_size:\n",
    "            scale = max(min_gaussian_size / width, min_gaussian_size / height)\n",
    "            width = max(int(width * scale), min_gaussian_size)\n",
    "            height = max(int(height * scale), min_gaussian_size)\n",
    "        \n",
    "        dst_points = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]], dtype=np.float32)\n",
    "\n",
    "        # ガウス分布を生成\n",
    "        x = np.linspace(-width / 2, width / 2, width)\n",
    "        y = np.linspace(-height / 2, height / 2, height)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        \n",
    "        # シグマ値の調整（小さすぎる場合は最小値を設定）\n",
    "        min_sigma = 1.0\n",
    "        sigma_x = max(width / 5.0, min_sigma)\n",
    "        sigma_y = max(height / 5.0, min_sigma)\n",
    "        \n",
    "        gaussian = amplitude * np.exp(-((x**2) / (2 * sigma_x**2) + (y**2) / (2 * sigma_y**2)))\n",
    "\n",
    "        try:\n",
    "            # Perspective Transformation行列を計算\n",
    "            matrix = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "\n",
    "            # 入力ガウシアンを適切な形式に変換\n",
    "            gaussian = gaussian.astype(np.float32)  # float32型に変換\n",
    "            \n",
    "            # ガウス分布をPerspective Transformationで変形\n",
    "            transformed_gaussian = cv2.warpPerspective(\n",
    "                gaussian,\n",
    "                matrix,\n",
    "                (canvas.shape[1], canvas.shape[0]),\n",
    "                flags=cv2.INTER_LINEAR,\n",
    "                borderMode=cv2.BORDER_CONSTANT,\n",
    "                borderValue=0\n",
    "            )\n",
    "\n",
    "            # キャンバスにガウス分布を追加\n",
    "            canvas += transformed_gaussian\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: perspective transformation failed - {e}\")\n",
    "            # エラーが発生した場合は、キャンバスをそのまま返す\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def design_gaussian_map(self, canvas, point_list):\n",
    "        for points in point_list:\n",
    "            p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y = points\n",
    "            self.add_perspective_gaussian_to_canvas(canvas, ((p1x, p1y), (p2x, p2y), (p3x, p3y), (p4x, p4y)), amplitude=1.0)\n",
    "        return canvas\n",
    "\n",
    "    def return_tensor_gt(self, gt_info_dic, image, original_size=None):\n",
    "        \"\"\"\n",
    "        正解マップを生成する\n",
    "        Args:\n",
    "            gt_info_dic: アノテーションデータ\n",
    "            image: リサイズ済みの画像\n",
    "            original_size: 元の画像サイズ（width, height）\n",
    "        \"\"\"\n",
    "        main_region, main_affinity, furi_region, furi_affinity = self.return_ground_truth_canvas(image)\n",
    "\n",
    "        # スケーリング係数を計算\n",
    "        if original_size:\n",
    "            orig_w, orig_h = original_size\n",
    "            current_w, current_h = image.size\n",
    "            scale_w = current_w / orig_w\n",
    "            scale_h = current_h / orig_h\n",
    "        else:\n",
    "            scale_w = scale_h = 1.0\n",
    "\n",
    "        # キャンバスマップを作成\n",
    "        canvas_list = []\n",
    "        canvas_map = {\n",
    "            'main_region': main_region,\n",
    "            'main_affinity': main_affinity,\n",
    "            'furi_region': furi_region,\n",
    "            'furi_affinity': furi_affinity\n",
    "        }\n",
    "        \n",
    "        for name, canvas in canvas_map.items():\n",
    "            if name in gt_info_dic:\n",
    "                # 座標をスケーリング\n",
    "                scaled_points = []\n",
    "                for points in gt_info_dic[name]:\n",
    "                    scaled_point = []\n",
    "                    for i, coord in enumerate(points):\n",
    "                        # 偶数インデックスはx座標、奇数インデックスはy座標\n",
    "                        scaled_coord = coord * (scale_w if i % 2 == 0 else scale_h)\n",
    "                        scaled_point.append(scaled_coord)\n",
    "                    scaled_points.append(scaled_point)\n",
    "                \n",
    "                canvas_list.append(self.design_gaussian_map(canvas, scaled_points))\n",
    "\n",
    "        # それぞれをtorch tensorに変換\n",
    "        tensor_list = []\n",
    "        for canvas in canvas_list:\n",
    "            tensor_list.append(torch.from_numpy(canvas.astype(np.float32)).clone())\n",
    "        \n",
    "        return_tensor = torch.stack(tensor_list)\n",
    "        return return_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d31f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5935776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json データを読み込みました。\n"
     ]
    }
   ],
   "source": [
    "test_doc_id_list = ['100241706', '100249371', '100249376', '100249416', '100249476', '100249537', '200003076', '200003803', '200003967', '200004107']\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = PreTrainDataset(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=False,\n",
    "    transform=transform,\n",
    "    target_width=300  # 横幅を300ピクセルに固定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0e4357",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:3376: error: (-215:Assertion failed) _src.total() > 0 in function 'cv::warpPerspective'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      9\u001b[0m start_memory \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m  \u001b[38;5;66;03m# MB単位\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m first_data \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[0;32m     13\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     14\u001b[0m end_memory \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\n",
      "Cell \u001b[1;32mIn[8], line 65\u001b[0m, in \u001b[0;36mPreTrainDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     62\u001b[0m image \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mresize(image, new_size, interpolation\u001b[38;5;241m=\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mInterpolationMode\u001b[38;5;241m.\u001b[39mBILINEAR)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# 4. リサイズ後のサイズで正解マップを生成\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m tensor_gt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_tensor_gt(\n\u001b[0;32m     66\u001b[0m     gt_info_dic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m'\u001b[39m][image_id],\n\u001b[0;32m     67\u001b[0m     image\u001b[38;5;241m=\u001b[39mimage,\n\u001b[0;32m     68\u001b[0m     original_size\u001b[38;5;241m=\u001b[39m(original_w, original_h)\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     72\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "Cell \u001b[1;32mIn[8], line 164\u001b[0m, in \u001b[0;36mPreTrainDataset.return_tensor_gt\u001b[1;34m(self, gt_info_dic, image, original_size)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 scaled_point\u001b[38;5;241m.\u001b[39mappend(scaled_coord)\n\u001b[0;32m    162\u001b[0m             scaled_points\u001b[38;5;241m.\u001b[39mappend(scaled_point)\n\u001b[1;32m--> 164\u001b[0m         canvas_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesign_gaussian_map(canvas, scaled_points))\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# それぞれをtorch tensorに変換\u001b[39;00m\n\u001b[0;32m    167\u001b[0m tensor_list \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[8], line 121\u001b[0m, in \u001b[0;36mPreTrainDataset.design_gaussian_map\u001b[1;34m(self, canvas, point_list)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m points \u001b[38;5;129;01min\u001b[39;00m point_list:\n\u001b[0;32m    120\u001b[0m     p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y \u001b[38;5;241m=\u001b[39m points\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_perspective_gaussian_to_canvas(canvas, ((p1x, p1y), (p2x, p2y), (p3x, p3y), (p4x, p4y)), amplitude\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m canvas\n",
      "Cell \u001b[1;32mIn[8], line 111\u001b[0m, in \u001b[0;36mPreTrainDataset.add_perspective_gaussian_to_canvas\u001b[1;34m(self, canvas, points, amplitude)\u001b[0m\n\u001b[0;32m    108\u001b[0m matrix \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetPerspectiveTransform(dst_points, src_points)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# ガウス分布をPerspective Transformationで変形\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m transformed_gaussian \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwarpPerspective(gaussian, matrix, (canvas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], canvas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# キャンバスにガウス分布を追加\u001b[39;00m\n\u001b[0;32m    114\u001b[0m canvas \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m transformed_gaussian\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:3376: error: (-215:Assertion failed) _src.total() > 0 in function 'cv::warpPerspective'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    start_memory = process.memory_info().rss / 1024 / 1024  # MB単位\n",
    "\n",
    "    first_data = dataset[i]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_memory = process.memory_info().rss / 1024 / 1024\n",
    "    \n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Memory change: {end_memory - start_memory:.2f} MB\")\n",
    "    print(f\"Output tensor shapes:\")\n",
    "    print(f\"Input image: {first_data[0].shape}\")\n",
    "    for j in range(4):\n",
    "        print(f\"GT channel {j}: {first_data[1][j].shape}\")\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(first_data[1][j])\n",
    "        plt.title(f\"Channel {j}\")\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kuzushiji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
