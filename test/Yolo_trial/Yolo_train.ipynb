{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5567cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics path: C:\\Users\\kotat\\MyPrograms\\MyKuzushiji\\ultralytics\\ultralytics\\__init__.py\n",
      "Current working directory: c:\\Users\\kotat\\MyPrograms\\MyKuzushiji\\Craft_respect\\test\\Yolo_trial\n",
      "Creating model from YAML...\n",
      "Model created successfully!\n",
      "Model head type: <class 'ultralytics.nn.modules.head.Detect'>\n",
      "Error occurred: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kotat\\\\MyPrograms\\\\MyKuzushiji\\\\Craft_respect\\\\test\\\\Yolo_trial\\\\ultralytics\\\\models\\\\yolo\\\\detect\\\\100241706_sep_100241706_00002_1.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kotat\\AppData\\Local\\Temp\\ipykernel_22152\\2099966471.py\", line 231, in <module>\n",
      "    image = Image.open(\"ultralytics/models/yolo/detect/100241706_sep_100241706_00002_1.jpg\")\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kotat\\AppData\\Local\\anaconda3\\envs\\kuzushiji\\Lib\\site-packages\\PIL\\Image.py\", line 3277, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kotat\\\\MyPrograms\\\\MyKuzushiji\\\\Craft_respect\\\\test\\\\Yolo_trial\\\\ultralytics\\\\models\\\\yolo\\\\detect\\\\100241706_sep_100241706_00002_1.jpg'\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "import random\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma: float = 1.5, alpha: float = 0.25):\n",
    "        \"\"\"Initialize FocalLoss class with focusing and balancing parameters.\"\"\"\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = torch.tensor(alpha)\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculate focal loss with modulating factors for class imbalance.\"\"\"\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, label, reduction=\"none\")\n",
    "        pred_prob = pred.sigmoid()  # prob from logits\n",
    "        p_t = label * pred_prob + (1 - label) * (1 - pred_prob)\n",
    "        modulating_factor = (1.0 - p_t) ** self.gamma\n",
    "        loss *= modulating_factor\n",
    "        if (self.alpha > 0).any():\n",
    "            self.alpha = self.alpha.to(device=pred.device, dtype=pred.dtype)\n",
    "            alpha_factor = label * self.alpha + (1 - label) * (1 - self.alpha)\n",
    "            loss *= alpha_factor\n",
    "        return loss.mean(1).sum()\n",
    "\n",
    "class HeatmapTrainer:  # BaseTrainerを継承しない\n",
    "    def __init__(self, model, loss_fn):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.model.to(self.device)\n",
    "        \n",
    "    def preprocess_batch(self, batch: Dict, img_size: tuple = (640, 640)) -> Dict:\n",
    "        \"\"\"\n",
    "        Preprocess a batch of images by scaling and converting to float.\n",
    "        \n",
    "        Args:\n",
    "            batch (Dict): Dictionary containing batch data with 'img' tensor.\n",
    "            img_size (tuple): Target size (resz_w, resz_h) for resizing.\n",
    "        \n",
    "        Returns:\n",
    "            (Dict): Preprocessed batch with resized images.\n",
    "        \"\"\"\n",
    "        resz_w, resz_h = img_size\n",
    "        \n",
    "        # torch.tensorをデバイスに移動\n",
    "        batch[\"img\"] = batch[\"img\"].to(self.device, non_blocking=True).float()\n",
    "        \n",
    "        # バッチサイズ、チャネル、高さ、幅を取得\n",
    "        batch_size, channels, img_h, img_w = batch[\"img\"].shape\n",
    "        \n",
    "        # アスペクト比を保持してリサイズするためのスケール計算\n",
    "        scale = min(resz_w / img_w, resz_h / img_h)\n",
    "        new_w = int(img_w * scale)\n",
    "        new_h = int(img_h * scale)\n",
    "        \n",
    "        # リサイズ\n",
    "        resized_imgs = F.interpolate(batch[\"img\"], size=(new_h, new_w), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # パディング計算\n",
    "        pad_w = resz_w - new_w\n",
    "        pad_h = resz_h - new_h\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        \n",
    "        # パディング適用 (left, right, top, bottom)\n",
    "        padded_imgs = F.pad(resized_imgs, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0)\n",
    "        \n",
    "        batch[\"img\"] = padded_imgs\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "    def forward_and_loss(self, batch, targets=None):\n",
    "        # モデルを学習モードに設定\n",
    "        self.model.model.train()\n",
    "        \n",
    "        # 1. 画像の推論（生の出力を取得）\n",
    "        # YOLOモデルの内部モデル（nn.Module）に直接アクセス\n",
    "        predictions = self.model.model(batch[\"img\"])\n",
    "        \n",
    "        print(f\"Raw predictions type: {type(predictions)}\")\n",
    "        print(f\"Raw predictions length: {len(predictions)}\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            print(f\"Prediction {i} shape: {pred.shape}\")\n",
    "        \n",
    "        # 2. ヒートマップ予測とロス計算（targetsがある場合）\n",
    "        if targets is not None:\n",
    "            loss = self.loss_fn(predictions, targets)\n",
    "            return predictions, loss\n",
    "        else:\n",
    "            return predictions, None\n",
    "\n",
    "# テスト用コードも修正\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # ローカルのultralyticsパスを最優先に設定\n",
    "    local_ultralytics_path = r\"C:\\Users\\kotat\\MyPrograms\\MyKuzushiji\\ultralytics\"\n",
    "    if local_ultralytics_path not in sys.path:\n",
    "        sys.path.insert(0, local_ultralytics_path)\n",
    "\n",
    "    # この後でインポート\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "    import ultralytics, os\n",
    "    print(f\"Ultralytics path: {ultralytics.__file__}\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    \n",
    "    try:\n",
    "        # YAMLファイルからモデルを作成\n",
    "        print(\"Creating model from YAML...\")\n",
    "        model = YOLO(\"yolov8n.yaml\") \n",
    "        print(\"Model created successfully!\")\n",
    "        \n",
    "        # モデル構造を確認\n",
    "        print(f\"Model head type: {type(model.model.model[-1])}\")\n",
    "        \n",
    "        fl = FocalLoss(gamma=2.0, alpha=0.25)\n",
    "        \n",
    "        # PIL ImageをTensorに変換\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        heat_obj = HeatmapTrainer(model=model, loss_fn=fl)\n",
    "\n",
    "\n",
    "        image = Image.open(\"ultralytics/models/yolo/detect/100241706_sep_100241706_00002_1.jpg\")\n",
    "        image_tensor = transform(image).unsqueeze(0)  # バッチ次元を追加\n",
    "        print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "        result = heat_obj.preprocess_batch({\"img\": image_tensor})\n",
    "        print(f\"Preprocessed batch shape: {result['img'].shape}\")\n",
    "        # 生の予測結果を取得\n",
    "        print(\"Running forward pass...\")\n",
    "        predictions, _ = heat_obj.forward_and_loss(result)\n",
    "        \n",
    "        # 各予測の詳細を表示\n",
    "        from matplotlib import pyplot as plt\n",
    "        for i, pred in enumerate(predictions):\n",
    "            print(f\"Level {i}: {pred.shape}\")\n",
    "            for i in range(4):\n",
    "                plt.subplot(1, 4, i + 1)\n",
    "                plt.imshow(pred[0, i].cpu().detach().numpy(), cmap='hot')\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# # テスト用コード\n",
    "# if __name__ == \"__main__\":\n",
    "#     from ultralytics import YOLO\n",
    "    \n",
    "#     model = YOLO(\"yolov8n.pt\")\n",
    "#     fl = FocalLoss(gamma=2.0, alpha=0.25)\n",
    "#     image = Image.open(\"ultralytics/models/yolo/detect/100241706_sep_100241706_00002_1.jpg\")\n",
    "    \n",
    "#     # PIL ImageをTensorに変換\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#     ])\n",
    "#     image_tensor = transform(image).unsqueeze(0)  # バッチ次元を追加\n",
    "    \n",
    "#     heat_obj = HeatmapTrainer(model=model, loss_fn=fl)\n",
    "#     result = heat_obj.preprocess_batch({\"img\": image_tensor})\n",
    "#     print(f\"Preprocessed batch shape: {result['img'].shape}\")\n",
    "\n",
    "#     pred = model(result[\"img\"])\n",
    "#     print(type(pred[0]))\n",
    "\n",
    "#     # print(torch.tensor(pred).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d4b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kuzushiji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
