{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7613827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from src.my_app import UNet, create_optimized_dataloader\n",
    "from src.my_app.core.MyDataset.OldMyDataset_speed import PreTrainDataset_old\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def crop_labels_to_match(labels_to_crop, target_tensor):\n",
    "    target_h, target_w = target_tensor.shape[2:]\n",
    "    source_h, source_w = labels_to_crop.shape[2:]\n",
    "    delta_h = (source_h - target_h) // 2\n",
    "    delta_w = (source_w - target_w) // 2\n",
    "    return labels_to_crop[:, :, delta_h:delta_h + target_h, delta_w:delta_w + target_w]\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resizeze((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# --- Dataset ---\n",
    "test_doc_id_list = [\n",
    "    '200021637',\n",
    "    '100249371',\n",
    "    '100249537',\n",
    "    '200005598',\n",
    "    '200014740',\n",
    "    '200020019',\n",
    "    '200021712',\n",
    "    '200021869'\n",
    "]\n",
    "train_dataset = dataset = PreTrainDataset_old(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=False,\n",
    "    # device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    precompute_gt=True,\n",
    "    transform=transform,\n",
    "    # target_width=400  # 横幅を400ピクセルに固定\n",
    ")\n",
    "\n",
    "test_dataset = PreTrainDataset_old(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=True,\n",
    "    # device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    precompute_gt=True,\n",
    "    transform=transform,\n",
    "    # target_width=400  # 横幅を400ピクセルに固定\n",
    ")\n",
    "\n",
    "\n",
    "# 最適化されたDataLoaderの作成\n",
    "train_dl = PreTrainDataset_old.create_optimized_dataloader_for_old_dataset(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=min(mp.cpu_count(), 4)\n",
    ")\n",
    "test_dl = PreTrainDataset_old.create_optimized_dataloader_for_old_dataset(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=min(mp.cpu_count(), 4)\n",
    ")\n",
    "# train_dl = create_optimized_dataloader(train_dataset, batch_size=1, num_workers=min(mp.cpu_count(), 4))\n",
    "# test_dl = create_optimized_dataloader(test_dataset, batch_size=1, num_workers=min(mp.cpu_count(), 4))\n",
    "\n",
    "# --- モデル、損失関数、最適化手法の定義 ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(3, 4).to(device)\n",
    "criterion = nn.MSELoss() # 回帰問題なのでMSE損失を使用\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- チェックポイントの設定 ---\n",
    "checkpoint_dir = \"../.checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 最良のモデルを追跡するための変数\n",
    "best_test_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "# チェックポイントの読み込み（存在する場合）\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"latest_checkpoint.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_test_loss = checkpoint['best_test_loss']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    test_loss_history = checkpoint['test_loss_history']\n",
    "    print(f\"チェックポイントを読み込みました（エポック {start_epoch}）\")\n",
    "\n",
    "num_epochs = 100 # エポック数を定義\n",
    "\n",
    "# 損失の履歴を保存するリストを初期化\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "print(\"学習を開始します...\")\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f'start epcoch')\n",
    "    # --- 訓練フェーズ ---\n",
    "    model.train() # モデルを訓練モードに設定\n",
    "    train_loss_total = 0\n",
    "    \n",
    "    # tqdmでプログレスバーを表示\n",
    "    train_bar = tqdm(train_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "    for imgs, masks in train_bar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        \n",
    "        preds = model(imgs)\n",
    "        cropped_masks = crop_labels_to_match(masks, preds)\n",
    "\n",
    "        loss = criterion(preds, cropped_masks)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_total += loss.item()\n",
    "        # プログレスバーに現在のロスを表示\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss_total / len(train_dl)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "\n",
    "    # --- 評価フェーズ ---\n",
    "    model.eval() # モデルを評価モードに設定\n",
    "    test_loss_total = 0\n",
    "    \n",
    "    # 勾配計算を無効化して、メモリ効率を良くする\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Test]\")\n",
    "        for imgs, masks in test_bar:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            preds = model(imgs)\n",
    "            cropped_masks = crop_labels_to_match(masks, preds)\n",
    "            \n",
    "            loss = criterion(preds, cropped_masks)\n",
    "            test_loss_total += loss.item()\n",
    "            test_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_test_loss = test_loss_total / len(test_dl)\n",
    "    test_loss_history.append(avg_test_loss)\n",
    "    \n",
    "    # 各エポックの最後に訓練ロスとテストロスを表示\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "    \n",
    "    # 最新のチェックポイントを保存\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'test_loss_history': test_loss_history,\n",
    "        'best_test_loss': best_test_loss\n",
    "    }, os.path.join(checkpoint_dir, \"latest_checkpoint.pth\"))\n",
    "    \n",
    "    # より良い性能が出た場合、ベストモデルとして保存\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'test_loss': avg_test_loss,\n",
    "        }, os.path.join(checkpoint_dir, \"best_model.pth\"))\n",
    "        print(f\"新しいベストモデルを保存しました（Test Loss: {avg_test_loss:.4f}）\")\n",
    "\n",
    "print(\"学習が完了しました。\")\n",
    "\n",
    "# --- 損失の推移をグラフで表示 ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(test_loss_history, label=\"Test Loss\")\n",
    "plt.title(\"Loss Trend\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
