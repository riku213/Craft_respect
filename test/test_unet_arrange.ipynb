{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a824e44",
   "metadata": {},
   "source": [
    "# 学習セッション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba43bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# プロジェクトのルートをCraft_respectに設定\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from src.my_app import UNet, PreTrainDataset, create_optimized_dataloader\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "def crop_labels_to_match(labels_to_crop, target_tensor):\n",
    "    target_h, target_w = target_tensor.shape[2:]\n",
    "    source_h, source_w = labels_to_crop.shape[2:]\n",
    "    delta_h = (source_h - target_h) // 2\n",
    "    delta_w = (source_w - target_w) // 2\n",
    "    return labels_to_crop[:, :, delta_h:delta_h + target_h, delta_w:delta_w + target_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d9129",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PreTrainDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n",
      "\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# --- Dataset ---\u001b[39;00m\n",
      "\u001b[1;32m     26\u001b[0m test_doc_id_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100241706\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100249371\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100249376\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100249416\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100249476\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m100249537\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m200003076\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m200003803\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m200003967\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m200004107\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m---> 27\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPreTrainDataset\u001b[49m(\n",
      "\u001b[1;32m     28\u001b[0m     input_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../kuzushiji-recognition/synthetic_images/input_images/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     29\u001b[0m     json_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../kuzushiji-recognition/synthetic_images/gt_json.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     30\u001b[0m     test_doc_id_list\u001b[38;5;241m=\u001b[39mtest_doc_id_list,\n",
      "\u001b[1;32m     31\u001b[0m     test_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m     32\u001b[0m     device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m),  \u001b[38;5;66;03m# GPUを明示的に指定\u001b[39;00m\n",
      "\u001b[1;32m     33\u001b[0m     precompute_gt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# 事前計算を有効化\u001b[39;00m\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# num_workers=None\u001b[39;00m\n",
      "\u001b[1;32m     35\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtransform,  \u001b[38;5;66;03m# 画像変換を追加\u001b[39;00m\n",
      "\u001b[1;32m     36\u001b[0m     target_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m\n",
      "\u001b[1;32m     37\u001b[0m )\n",
      "\u001b[1;32m     38\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m PreTrainDataset(\n",
      "\u001b[1;32m     39\u001b[0m     input_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../kuzushiji-recognition/synthetic_images/input_images/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     40\u001b[0m     json_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../kuzushiji-recognition/synthetic_images/gt_json.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     47\u001b[0m     target_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m\n",
      "\u001b[1;32m     48\u001b[0m )\n",
      "\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 最適化されたDataLoaderの作成\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PreTrainDataset' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# テストデータのドキュメントIDを指定\n",
    "test_doc_id_list = [\n",
    "    '100241706', \n",
    "    '100249371', \n",
    "    '100249376', \n",
    "    '100249416', \n",
    "    '100249476', \n",
    "    '100249537', \n",
    "    '200003076', \n",
    "    '200003803', \n",
    "    '200003967', \n",
    "    '200004107'\n",
    "]\n",
    "train_dataset = PreTrainDataset(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=False,\n",
    "    device=torch.device('cuda'),  # GPUを明示的に指定\n",
    "    precompute_gt=False,  # 事前計算を有効化\n",
    "    # num_workers=None\n",
    "    transform=transform,  # 画像変換を追加\n",
    "    target_width=300\n",
    ")\n",
    "test_dataset = PreTrainDataset(\n",
    "    input_path='../../kuzushiji-recognition/synthetic_images/input_images/',\n",
    "    json_path='../../kuzushiji-recognition/synthetic_images/gt_json.json',\n",
    "    test_doc_id_list=test_doc_id_list,\n",
    "    test_mode=True,\n",
    "    device=torch.device('cuda'),  # GPUを明示的に指定\n",
    "    precompute_gt=False,  # 事前計算を有効化\n",
    "    # num_workers=4\n",
    "    transform=transform,  # 画像変換を追加\n",
    "    target_width=300\n",
    ")\n",
    "\n",
    "# 最適化されたDataLoaderの作成\n",
    "train_dl = create_optimized_dataloader(train_dataset, batch_size=1, num_workers=min(mp.cpu_count(), 4))\n",
    "test_dl = create_optimized_dataloader(test_dataset, batch_size=1, num_workers=min(mp.cpu_count(), 4))\n",
    "\n",
    "# --- モデル、損失関数、最適化手法の定義 ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(3, 4).to(device)\n",
    "criterion = nn.MSELoss() # 回帰問題なのでMSE損失を使用\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- チェックポイントの設定 ---\n",
    "checkpoint_dir = \"../.checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 最良のモデルを追跡するための変数\n",
    "best_test_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "# チェックポイントの読み込み（存在する場合）\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"latest_checkpoint.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_test_loss = checkpoint['best_test_loss']\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    test_loss_history = checkpoint['test_loss_history']\n",
    "    print(f\"チェックポイントを読み込みました（エポック {start_epoch}）\")\n",
    "\n",
    "print(\"学習を開始します...\")\n",
    "num_epochs = 100 # エポック数を定義\n",
    "\n",
    "# 損失の履歴を保存するリストを初期化\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "print(\"学習を開始します...\")\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f'start epcoch')\n",
    "    # --- 訓練フェーズ ---\n",
    "    model.train() # モデルを訓練モードに設定\n",
    "    train_loss_total = 0\n",
    "    \n",
    "    # tqdmでプログレスバーを表示\n",
    "    train_bar = tqdm(train_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "    for imgs, masks in train_bar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        \n",
    "        preds = model(imgs)\n",
    "        cropped_masks = crop_labels_to_match(masks, preds)\n",
    "\n",
    "        loss = criterion(preds, cropped_masks)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_total += loss.item()\n",
    "        # プログレスバーに現在のロスを表示\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss_total / len(train_dl)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "\n",
    "    # --- 評価フェーズ ---\n",
    "    model.eval() # モデルを評価モードに設定\n",
    "    test_loss_total = 0\n",
    "    \n",
    "    # 勾配計算を無効化して、メモリ効率を良くする\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_dl, desc=f\"Epoch {epoch+1}/{num_epochs} [Test]\")\n",
    "        for imgs, masks in test_bar:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            preds = model(imgs)\n",
    "            cropped_masks = crop_labels_to_match(masks, preds)\n",
    "            \n",
    "            loss = criterion(preds, cropped_masks)\n",
    "            test_loss_total += loss.item()\n",
    "            test_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_test_loss = test_loss_total / len(test_dl)\n",
    "    test_loss_history.append(avg_test_loss)\n",
    "    \n",
    "    # 各エポックの最後に訓練ロスとテストロスを表示\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "    \n",
    "    # 最新のチェックポイントを保存\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'test_loss_history': test_loss_history,\n",
    "        'best_test_loss': best_test_loss\n",
    "    }, os.path.join(checkpoint_dir, \"latest_checkpoint.pth\"))\n",
    "    \n",
    "    # より良い性能が出た場合、ベストモデルとして保存\n",
    "    if avg_test_loss < best_test_loss:\n",
    "        best_test_loss = avg_test_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'test_loss': avg_test_loss,\n",
    "        }, os.path.join(checkpoint_dir, \"best_model.pth\"))\n",
    "        print(f\"新しいベストモデルを保存しました（Test Loss: {avg_test_loss:.4f}）\")\n",
    "\n",
    "print(\"学習が完了しました。\")\n",
    "\n",
    "# --- 損失の推移をグラフで表示 ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(test_loss_history, label=\"Test Loss\")\n",
    "plt.title(\"Loss Trend\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
