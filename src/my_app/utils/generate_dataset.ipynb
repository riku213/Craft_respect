{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfa7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files_and_dirs(path):\n",
    "    try:\n",
    "        items = os.listdir(path)\n",
    "        for item in items:\n",
    "            print(item)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}\")\n",
    "    except NotADirectoryError:\n",
    "        print(f\"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {path}\")\n",
    "    except PermissionError:\n",
    "        print(f\"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©ãŒã‚ã‚Šã¾ã›ã‚“: {path}\")\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "# list_files_and_dirs('/path/to/directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3bf95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "100241706\n"
     ]
    }
   ],
   "source": [
    "list_files_and_dirs('../../../../kuzushiji-recognition/char_sep_datas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7718ff42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œèª¿æŸ» ===\n",
      "\n",
      "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: 76\n",
      "æœ€åˆã®5ã¤ã®ç”»åƒID: ['100241706_sep_100241706_00027_1', '100241706_sep_100241706_00018_2', '100241706_sep_100241706_00003_1', '100241706_sep_100241706_00025_2', '100241706_sep_100241706_00027_2']\n",
      "\n",
      "JSONãƒ•ã‚¡ã‚¤ãƒ«å†…ã®IDæ•°: 76\n",
      "æœ€åˆã®5ã¤ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ID: ['100241706_sep_100241706_00003_1', '100241706_sep_100241706_00025_2', '100241706_sep_100241706_00018_2', '100241706_sep_100241706_00027_1', '100241706_sep_100241706_00025_1']\n",
      "\n",
      "=== IDå½¢å¼ã®åˆ†æ ===\n",
      "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«IDã®ä¾‹:\n",
      "  1: '100241706_sep_100241706_00027_1'\n",
      "  2: '100241706_sep_100241706_00018_2'\n",
      "  3: '100241706_sep_100241706_00003_1'\n",
      "  4: '100241706_sep_100241706_00025_2'\n",
      "  5: '100241706_sep_100241706_00027_2'\n",
      "\n",
      "JSONãƒ•ã‚¡ã‚¤ãƒ«IDã®ä¾‹:\n",
      "  1: '100241706_sep_100241706_00003_1'\n",
      "  2: '100241706_sep_100241706_00025_2'\n",
      "  3: '100241706_sep_100241706_00018_2'\n",
      "  4: '100241706_sep_100241706_00027_1'\n",
      "  5: '100241706_sep_100241706_00025_1'\n",
      "\n",
      "=== IDå¯¾å¿œé–¢ä¿‚ã®ç¢ºèª ===\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00027_1' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00018_2' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00003_1' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00025_2' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00027_2' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00018_1' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00025_1' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00003_2' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00021_1' â†’ JSONå†…ã«å­˜åœ¨\n",
      "âœ“ ç”»åƒID '100241706_sep_100241706_00007_2' â†’ JSONå†…ã«å­˜åœ¨\n",
      "\n",
      "=== IDå¤‰æ›è¦å‰‡ã®æ¨æ¸¬ ===\n",
      "JSONãƒ•ã‚¡ã‚¤ãƒ«IDä¾‹: '100241706_sep_100241706_00003_1'\n",
      "  '_sep_'ã§åˆ†å‰²: ['100241706', '100241706_00003_1']\n",
      "  æ¨æ¸¬ã•ã‚Œã‚‹å¤‰æ›: doc_id='100241706', file_part='100241706_00003_1'\n",
      "  âœ— å¯¾å¿œç”»åƒãƒ•ã‚¡ã‚¤ãƒ«è¦‹ã¤ã‹ã‚‰ãªã„: '100241706_00003_1'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def investigate_image_annotation_mismatch():\n",
    "    \"\"\"ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œé–¢ä¿‚ã‚’èª¿æŸ»\"\"\"\n",
    "    \n",
    "    # ãƒ‘ã‚¹ã®è¨­å®š\n",
    "    input_images_path = '../../../../kuzushiji-recognition/synthetic_images/input_images/'\n",
    "    json_path = '../../../../kuzushiji-recognition/synthetic_images/gt_json.json'\n",
    "    \n",
    "    print(\"=== ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œèª¿æŸ» ===\\n\")\n",
    "    \n",
    "    # 1. ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—\n",
    "    if os.path.exists(input_images_path):\n",
    "        image_files = glob.glob(os.path.join(input_images_path, \"*.jpg\"))\n",
    "        image_ids = [os.path.basename(f).replace('.jpg', '') for f in image_files]\n",
    "        print(f\"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(image_files)}\")\n",
    "        print(f\"æœ€åˆã®5ã¤ã®ç”»åƒID: {image_ids[:5]}\")\n",
    "    else:\n",
    "        print(f\"ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_images_path}\")\n",
    "        return\n",
    "    \n",
    "    # 2. JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        json_file_ids = list(json_data.get('files', {}).keys())\n",
    "        print(f\"\\nJSONãƒ•ã‚¡ã‚¤ãƒ«å†…ã®IDæ•°: {len(json_file_ids)}\")\n",
    "        print(f\"æœ€åˆã®5ã¤ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ID: {json_file_ids[:5]}\")\n",
    "    else:\n",
    "        print(f\"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_path}\")\n",
    "        return\n",
    "    \n",
    "    # 3. IDå½¢å¼ã®åˆ†æ\n",
    "    print(\"\\n=== IDå½¢å¼ã®åˆ†æ ===\")\n",
    "    print(\"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«IDã®ä¾‹:\")\n",
    "    for i, img_id in enumerate(image_ids[:5]):\n",
    "        print(f\"  {i+1}: '{img_id}'\")\n",
    "    \n",
    "    print(\"\\nJSONãƒ•ã‚¡ã‚¤ãƒ«IDã®ä¾‹:\")\n",
    "    for i, json_id in enumerate(json_file_ids[:5]):\n",
    "        print(f\"  {i+1}: '{json_id}'\")\n",
    "    \n",
    "    # 4. IDå¯¾å¿œé–¢ä¿‚ã®ç¢ºèª\n",
    "    print(\"\\n=== IDå¯¾å¿œé–¢ä¿‚ã®ç¢ºèª ===\")\n",
    "    \n",
    "    # ç”»åƒIDã«å¯¾å¿œã™ã‚‹JSONã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "    missing_in_json = []\n",
    "    for img_id in image_ids[:10]:  # æœ€åˆã®10å€‹ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "        if img_id in json_data.get('files', {}):\n",
    "            print(f\"âœ“ ç”»åƒID '{img_id}' â†’ JSONå†…ã«å­˜åœ¨\")\n",
    "        else:\n",
    "            # é¡ä¼¼IDã‚’æ¢ã™\n",
    "            similar_ids = [jid for jid in json_file_ids if img_id in jid or jid in img_id]\n",
    "            if similar_ids:\n",
    "                print(f\"âœ— ç”»åƒID '{img_id}' â†’ JSONå†…ã«ç›´æ¥å¯¾å¿œãªã—\")\n",
    "                print(f\"    é¡ä¼¼ID: {similar_ids[:3]}\")\n",
    "            else:\n",
    "                print(f\"âœ— ç”»åƒID '{img_id}' â†’ JSONå†…ã«å¯¾å¿œãªã—\")\n",
    "                missing_in_json.append(img_id)\n",
    "    \n",
    "    # 5. JSONã®IDã§ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›è¦å‰‡ã‚’æ¨æ¸¬\n",
    "    print(\"\\n=== IDå¤‰æ›è¦å‰‡ã®æ¨æ¸¬ ===\")\n",
    "    if json_file_ids:\n",
    "        sample_json_id = json_file_ids[0]\n",
    "        print(f\"JSONãƒ•ã‚¡ã‚¤ãƒ«IDä¾‹: '{sample_json_id}'\")\n",
    "        \n",
    "        # '_sep_' ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "        if '_sep_' in sample_json_id:\n",
    "            parts = sample_json_id.split('_sep_')\n",
    "            print(f\"  '_sep_'ã§åˆ†å‰²: {parts}\")\n",
    "            if len(parts) == 2:\n",
    "                doc_id, file_part = parts\n",
    "                print(f\"  æ¨æ¸¬ã•ã‚Œã‚‹å¤‰æ›: doc_id='{doc_id}', file_part='{file_part}'\")\n",
    "                \n",
    "                # å¯¾å¿œã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¨æ¸¬\n",
    "                expected_image_id = file_part  # ã¾ãŸã¯åˆ¥ã®å¤‰æ›è¦å‰‡\n",
    "                if expected_image_id in image_ids:\n",
    "                    print(f\"  âœ“ å¯¾å¿œç”»åƒãƒ•ã‚¡ã‚¤ãƒ«è¦‹ã¤ã‹ã‚‹: '{expected_image_id}'\")\n",
    "                else:\n",
    "                    print(f\"  âœ— å¯¾å¿œç”»åƒãƒ•ã‚¡ã‚¤ãƒ«è¦‹ã¤ã‹ã‚‰ãªã„: '{expected_image_id}'\")\n",
    "    \n",
    "    return {\n",
    "        'image_ids': image_ids,\n",
    "        'json_file_ids': json_file_ids,\n",
    "        'missing_in_json': missing_in_json\n",
    "    }\n",
    "\n",
    "# èª¿æŸ»å®Ÿè¡Œ\n",
    "result = investigate_image_annotation_mismatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9116a08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IDç”Ÿæˆéç¨‹ã®èª¿æŸ» ===\n",
      "\n",
      "IDç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:\n",
      "  ãƒ‘ã‚¹: /path/to/100241706/images/100241706_00003_1.jpg\n",
      "  ç”ŸæˆID: '100241706_sep_100241706_00003_1'\n",
      "\n",
      "  ãƒ‘ã‚¹: /path/to/100241706/images/100241706_00025_2.jpg\n",
      "  ç”ŸæˆID: '100241706_sep_100241706_00025_2'\n",
      "\n",
      "  ãƒ‘ã‚¹: /path/to/100249371/images/100249371_00001_1.jpg\n",
      "  ç”ŸæˆID: '100249371_sep_100249371_00001_1'\n",
      "\n",
      "=== ä¸¦è¡Œå‡¦ç†å•é¡Œã®èª¿æŸ» ===\n",
      "\n",
      "doc_idåˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°:\n",
      "  100241706: 76å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«\n",
      "    - 100241706_sep_100241706_00003_1\n",
      "    - 100241706_sep_100241706_00025_2\n",
      "    - 100241706_sep_100241706_00018_2\n",
      "    ... ä»–73å€‹\n",
      "\n",
      "=== ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ãƒã‚§ãƒƒã‚¯ ===\n",
      "ãƒ•ã‚¡ã‚¤ãƒ«ID: 100241706_sep_100241706_00003_1\n",
      "  main_regionæ•°: 361\n",
      "  main_affinityæ•°: 342\n",
      "  furi_regionæ•°: 786\n",
      "  furi_affinityæ•°: 472\n",
      "  æœ€åˆã®regionåº§æ¨™: [222, 430, 347, 430, 347, 549, 222, 549]\n",
      "\n",
      "ãƒ•ã‚¡ã‚¤ãƒ«ID: 100241706_sep_100241706_00025_2\n",
      "  main_regionæ•°: 155\n",
      "  main_affinityæ•°: 142\n",
      "  furi_regionæ•°: 278\n",
      "  furi_affinityæ•°: 139\n",
      "  æœ€åˆã®regionåº§æ¨™: [393, 521, 509, 521, 509, 621, 393, 621]\n",
      "\n",
      "ãƒ•ã‚¡ã‚¤ãƒ«ID: 100241706_sep_100241706_00018_2\n",
      "  main_regionæ•°: 251\n",
      "  main_affinityæ•°: 234\n",
      "  furi_regionæ•°: 453\n",
      "  furi_affinityæ•°: 232\n",
      "  æœ€åˆã®regionåº§æ¨™: [220, 757, 315, 757, 315, 849, 220, 849]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def investigate_id_generation_process():\n",
    "    \"\"\"IDç”Ÿæˆéç¨‹ã®å•é¡Œã‚’èª¿æŸ»\"\"\"\n",
    "    \n",
    "    print(\"=== IDç”Ÿæˆéç¨‹ã®èª¿æŸ» ===\\n\")\n",
    "    \n",
    "    # generate_dateset.pyã®IDç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å†ç¾\n",
    "    def simulate_id_generation(file_path):\n",
    "        \"\"\"IDç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\"\"\"\n",
    "        doc_id = file_path.split('/')[-3]\n",
    "        file_id = str(doc_id) + '_sep_' + file_path.split('/')[-1].split('.')[0]\n",
    "        return file_id\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã§ãƒ†ã‚¹ãƒˆ\n",
    "    sample_paths = [\n",
    "        '/path/to/100241706/images/100241706_00003_1.jpg',\n",
    "        '/path/to/100241706/images/100241706_00025_2.jpg',\n",
    "        '/path/to/100249371/images/100249371_00001_1.jpg'\n",
    "    ]\n",
    "    \n",
    "    print(\"IDç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:\")\n",
    "    for path in sample_paths:\n",
    "        generated_id = simulate_id_generation(path)\n",
    "        print(f\"  ãƒ‘ã‚¹: {path}\")\n",
    "        print(f\"  ç”ŸæˆID: '{generated_id}'\")\n",
    "        print()\n",
    "    \n",
    "    return\n",
    "\n",
    "def check_concurrent_processing_issues():\n",
    "    \"\"\"ä¸¦è¡Œå‡¦ç†ã§ã®å•é¡Œã‚’èª¿æŸ»\"\"\"\n",
    "    \n",
    "    print(\"=== ä¸¦è¡Œå‡¦ç†å•é¡Œã®èª¿æŸ» ===\\n\")\n",
    "    \n",
    "    json_path = '../../../../kuzushiji-recognition/synthetic_images/gt_json.json'\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_path}\")\n",
    "        return\n",
    "    \n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # 1. åŒã˜doc_idã‚’æŒã¤ã‚¨ãƒ³ãƒˆãƒªã‚’åˆ†æ\n",
    "    doc_id_groups = {}\n",
    "    for file_id in json_data.get('files', {}).keys():\n",
    "        if '_sep_' in file_id:\n",
    "            doc_id = file_id.split('_sep_')[0]\n",
    "            if doc_id not in doc_id_groups:\n",
    "                doc_id_groups[doc_id] = []\n",
    "            doc_id_groups[doc_id].append(file_id)\n",
    "    \n",
    "    print(\"doc_idåˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°:\")\n",
    "    for doc_id, file_ids in doc_id_groups.items():\n",
    "        print(f\"  {doc_id}: {len(file_ids)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "        if len(file_ids) <= 5:  # å°‘ãªã„å ´åˆã¯å…¨ã¦è¡¨ç¤º\n",
    "            for fid in file_ids:\n",
    "                print(f\"    - {fid}\")\n",
    "        else:  # å¤šã„å ´åˆã¯æœ€åˆã®3å€‹ã ã‘\n",
    "            for fid in file_ids[:3]:\n",
    "                print(f\"    - {fid}\")\n",
    "            print(f\"    ... ä»–{len(file_ids)-3}å€‹\")\n",
    "        print()\n",
    "    \n",
    "    # 2. ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "    print(\"=== ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ãƒã‚§ãƒƒã‚¯ ===\")\n",
    "    sample_ids = list(json_data.get('files', {}).keys())[:3]\n",
    "    \n",
    "    for file_id in sample_ids:\n",
    "        data = json_data['files'][file_id]\n",
    "        print(f\"ãƒ•ã‚¡ã‚¤ãƒ«ID: {file_id}\")\n",
    "        print(f\"  main_regionæ•°: {len(data.get('main_region', []))}\")\n",
    "        print(f\"  main_affinityæ•°: {len(data.get('main_affinity', []))}\")\n",
    "        print(f\"  furi_regionæ•°: {len(data.get('furi_region', []))}\")\n",
    "        print(f\"  furi_affinityæ•°: {len(data.get('furi_affinity', []))}\")\n",
    "        \n",
    "        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯\n",
    "        if data.get('main_region'):\n",
    "            first_region = data['main_region'][0]\n",
    "            print(f\"  æœ€åˆã®regionåº§æ¨™: {first_region}\")\n",
    "            \n",
    "            # åº§æ¨™ãŒç”»åƒã‚µã‚¤ã‚ºå†…ã«åã¾ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "            # (é€šå¸¸ã¯0-æ•°åƒã®ç¯„å›²)\n",
    "            coords = [float(x) for x in first_region]\n",
    "            if any(c < 0 or c > 10000 for c in coords):\n",
    "                print(f\"  âš ï¸ ç•°å¸¸ãªåº§æ¨™å€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {coords}\")\n",
    "        print()\n",
    "    \n",
    "    return doc_id_groups\n",
    "\n",
    "# èª¿æŸ»å®Ÿè¡Œ\n",
    "investigate_id_generation_process()\n",
    "doc_groups = check_concurrent_processing_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f5a691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä¸¦è¡Œå‡¦ç†ãƒªã‚¹ã‚¯åˆ†æ ===\n",
      "\n",
      "ğŸ” generate_dateset.pyã®ä¸¦è¡Œå‡¦ç†æ§‹é€ :\n",
      "\n",
      "    mainé–¢æ•°:\n",
      "    â”œâ”€â”€ ProcessPoolExecutor(max_workers=20)  â† 20ä¸¦åˆ—ãƒ—ãƒ­ã‚»ã‚¹\n",
      "    â”‚   â”œâ”€â”€ process1: main_exe_for_one_image()\n",
      "    â”‚   â”œâ”€â”€ process2: main_exe_for_one_image()\n",
      "    â”‚   â”œâ”€â”€ ...\n",
      "    â”‚   â””â”€â”€ process20: main_exe_for_one_image()\n",
      "    â”‚\n",
      "    â””â”€â”€ å„ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒã˜JSONãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
      "        â””â”€â”€ update_json_data() â† ã“ã“ã§ç«¶åˆç™ºç”Ÿã®å¯èƒ½æ€§\n",
      "    \n",
      "âš ï¸ ç‰¹å®šã•ã‚ŒãŸå•é¡Œç‚¹:\n",
      "\n",
      "1. ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ç«¶åˆã€‘\n",
      "   - 20å€‹ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒæ™‚ã«åŒã˜JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹\n",
      "   - 'with lock:' ã¯ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯ã§ã¯ãªãã‚¹ãƒ¬ãƒƒãƒ‰é–“ãƒ­ãƒƒã‚¯\n",
      "   - multiprocessing.Manager().Lock() ãŒå¿…è¦\n",
      "\n",
      "2. ã€JSONãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“èª­ã¿æ›¸ãã€‘\n",
      "   - update_json_data()ã§æ¯å›JSONãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’èª­ã¿è¾¼ã¿\n",
      "   - json_data['files'][file_id] = data ã§ä¸Šæ›¸ã\n",
      "   - åŒæ™‚æ›¸ãè¾¼ã¿ã§ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã‚‹å¯èƒ½æ€§\n",
      "\n",
      "3. ã€ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã€‘\n",
      "   ãƒ—ãƒ­ã‚»ã‚¹A: JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ â†’ å‡¦ç†ä¸­\n",
      "   ãƒ—ãƒ­ã‚»ã‚¹B: åŒã˜JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ â†’ å‡¦ç†ä¸­\n",
      "   ãƒ—ãƒ­ã‚»ã‚¹A: ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã—ã¦ä¿å­˜\n",
      "   ãƒ—ãƒ­ã‚»ã‚¹B: å¤ã„ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã—ã¦ä¿å­˜ â† ãƒ—ãƒ­ã‚»ã‚¹Aã®å¤‰æ›´ãŒæ¶ˆå¤±\n",
      "\n",
      "4. ã€IDé‡è¤‡ã®å¯èƒ½æ€§ã€‘\n",
      "   - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è§£æã§ã®doc_idå–å¾—\n",
      "   - åŒã˜doc_idã®ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚¿ã‚¤ãƒŸãƒ³ã‚°\n",
      "   - ä¸¦è¡Œå‡¦ç†ã§ã®ä¸Šæ›¸ãç«¶åˆ\n",
      "\n",
      "=== ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===\n",
      "\n",
      "ã€æ­£å¸¸ãªå‡¦ç†é †åºã€‘\n",
      "æ™‚åˆ»1: ãƒ—ãƒ­ã‚»ã‚¹A - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {}\n",
      "æ™‚åˆ»2: ãƒ—ãƒ­ã‚»ã‚¹A - image1ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
      "æ™‚åˆ»3: ãƒ—ãƒ­ã‚»ã‚¹A - JSONã«{'image1': data1}è¿½åŠ ä¿å­˜\n",
      "æ™‚åˆ»4: ãƒ—ãƒ­ã‚»ã‚¹B - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {'image1': data1}\n",
      "æ™‚åˆ»5: ãƒ—ãƒ­ã‚»ã‚¹B - image2ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
      "æ™‚åˆ»6: ãƒ—ãƒ­ã‚»ã‚¹B - JSONã«{'image1': data1, 'image2': data2}ä¿å­˜\n",
      "\n",
      "ã€å•é¡Œã®ã‚ã‚‹å‡¦ç†é †åºï¼ˆãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ï¼‰ã€‘\n",
      "æ™‚åˆ»1: ãƒ—ãƒ­ã‚»ã‚¹A - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {}\n",
      "æ™‚åˆ»2: ãƒ—ãƒ­ã‚»ã‚¹B - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {} (åŒã˜ç©ºãƒ‡ãƒ¼ã‚¿)\n",
      "æ™‚åˆ»3: ãƒ—ãƒ­ã‚»ã‚¹A - image1ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
      "æ™‚åˆ»4: ãƒ—ãƒ­ã‚»ã‚¹B - image2ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
      "æ™‚åˆ»5: ãƒ—ãƒ­ã‚»ã‚¹A - JSONã«{'image1': data1}ä¿å­˜\n",
      "æ™‚åˆ»6: ãƒ—ãƒ­ã‚»ã‚¹B - JSONã«{'image2': data2}ä¿å­˜ â† image1ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆå¤±!\n",
      "æ™‚åˆ»7: ã¾ãŸã¯ã€ãƒ—ãƒ­ã‚»ã‚¹BãŒimage1ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’image2ã«èª¤ã£ã¦çµåˆ\n",
      "\n",
      "ã€çµæœã€‘\n",
      "- image1ã®ç”»åƒã«ã€image2ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒçµã³ä»˜ã\n",
      "- ã¾ãŸã¯ã€image1ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œå…¨ã«å¤±ã‚ã‚Œã‚‹\n",
      "- JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯image2ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿æ®‹ã‚‹\n",
      "\n",
      "=== è§£æ±ºç­–ã®ææ¡ˆ ===\n",
      "\n",
      "ğŸ”§ ã€ç·Šæ€¥å¯¾ç­–ã€‘\n",
      "1. ä¸¦è¡Œå‡¦ç†ã‚’ç„¡åŠ¹åŒ–\n",
      "   - max_workers=1 ã«è¨­å®š\n",
      "   - ã¾ãŸã¯ ProcessPoolExecutor ã‚’ä½¿ã‚ãšé †æ¬¡å‡¦ç†\n",
      "\n",
      "2. ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯ã®å®Ÿè£…\n",
      "\n",
      "    from multiprocessing import Manager\n",
      "    \n",
      "    if __name__ == \"__main__\":\n",
      "        with Manager() as manager:\n",
      "            file_lock = manager.Lock()  # ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯\n",
      "            with ProcessPoolExecutor(max_workers=20) as executor:\n",
      "                futures = []\n",
      "                for file_path in file_path_list:\n",
      "                    futures.append(executor.submit(\n",
      "                        main_exe_for_one_image,\n",
      "                        file_path=file_path,\n",
      "                        json_gt=json_gt,\n",
      "                        file_lock=file_lock  # ãƒ­ãƒƒã‚¯ã‚’æ¸¡ã™\n",
      "                    ))\n",
      "    \n",
      "3. å€‹åˆ¥JSONãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼\n",
      "   - å„ç”»åƒã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
      "   - æœ€å¾Œã«å…¨ã¦ã‚’çµ±åˆ\n",
      "   - ä¾‹: image1.json, image2.json â†’ æœ€çµ‚çš„ã«çµ±åˆ\n",
      "\n",
      "ğŸ”§ ã€æ ¹æœ¬çš„è§£æ±ºç­–ã€‘\n",
      "1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½¿ç”¨ (SQLite)\n",
      "2. ã‚­ãƒ¥ãƒ¼æ–¹å¼ã§ã®é †æ¬¡æ›¸ãè¾¼ã¿\n",
      "3. äº‹å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«IDãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate_dateset.pyã®ä¸¦è¡Œå‡¦ç†å•é¡Œã‚’è©³ç´°èª¿æŸ»\n",
    "def analyze_concurrent_processing_risks():\n",
    "    \"\"\"generate_dateset.pyã®ä¸¦è¡Œå‡¦ç†ãƒªã‚¹ã‚¯ã‚’åˆ†æ\"\"\"\n",
    "    \n",
    "    print(\"=== ä¸¦è¡Œå‡¦ç†ãƒªã‚¹ã‚¯åˆ†æ ===\\n\")\n",
    "    \n",
    "    print(\"ğŸ” generate_dateset.pyã®ä¸¦è¡Œå‡¦ç†æ§‹é€ :\")\n",
    "    print(\"\"\"\n",
    "    mainé–¢æ•°:\n",
    "    â”œâ”€â”€ ProcessPoolExecutor(max_workers=20)  â† 20ä¸¦åˆ—ãƒ—ãƒ­ã‚»ã‚¹\n",
    "    â”‚   â”œâ”€â”€ process1: main_exe_for_one_image()\n",
    "    â”‚   â”œâ”€â”€ process2: main_exe_for_one_image()\n",
    "    â”‚   â”œâ”€â”€ ...\n",
    "    â”‚   â””â”€â”€ process20: main_exe_for_one_image()\n",
    "    â”‚\n",
    "    â””â”€â”€ å„ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒã˜JSONãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
    "        â””â”€â”€ update_json_data() â† ã“ã“ã§ç«¶åˆç™ºç”Ÿã®å¯èƒ½æ€§\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"âš ï¸ ç‰¹å®šã•ã‚ŒãŸå•é¡Œç‚¹:\\n\")\n",
    "    \n",
    "    print(\"1. ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ç«¶åˆã€‘\")\n",
    "    print(\"   - 20å€‹ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒæ™‚ã«åŒã˜JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹\")\n",
    "    print(\"   - 'with lock:' ã¯ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯ã§ã¯ãªãã‚¹ãƒ¬ãƒƒãƒ‰é–“ãƒ­ãƒƒã‚¯\")\n",
    "    print(\"   - multiprocessing.Manager().Lock() ãŒå¿…è¦\\n\")\n",
    "    \n",
    "    print(\"2. ã€JSONãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“èª­ã¿æ›¸ãã€‘\")\n",
    "    print(\"   - update_json_data()ã§æ¯å›JSONãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’èª­ã¿è¾¼ã¿\")\n",
    "    print(\"   - json_data['files'][file_id] = data ã§ä¸Šæ›¸ã\")\n",
    "    print(\"   - åŒæ™‚æ›¸ãè¾¼ã¿ã§ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã‚‹å¯èƒ½æ€§\\n\")\n",
    "    \n",
    "    print(\"3. ã€ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã€‘\")\n",
    "    print(\"   ãƒ—ãƒ­ã‚»ã‚¹A: JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ â†’ å‡¦ç†ä¸­\")\n",
    "    print(\"   ãƒ—ãƒ­ã‚»ã‚¹B: åŒã˜JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ â†’ å‡¦ç†ä¸­\")\n",
    "    print(\"   ãƒ—ãƒ­ã‚»ã‚¹A: ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã—ã¦ä¿å­˜\")\n",
    "    print(\"   ãƒ—ãƒ­ã‚»ã‚¹B: å¤ã„ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã—ã¦ä¿å­˜ â† ãƒ—ãƒ­ã‚»ã‚¹Aã®å¤‰æ›´ãŒæ¶ˆå¤±\\n\")\n",
    "    \n",
    "    print(\"4. ã€IDé‡è¤‡ã®å¯èƒ½æ€§ã€‘\")\n",
    "    print(\"   - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è§£æã§ã®doc_idå–å¾—\")\n",
    "    print(\"   - åŒã˜doc_idã®ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚¿ã‚¤ãƒŸãƒ³ã‚°\")\n",
    "    print(\"   - ä¸¦è¡Œå‡¦ç†ã§ã®ä¸Šæ›¸ãç«¶åˆ\\n\")\n",
    "\n",
    "def simulate_race_condition():\n",
    "    \"\"\"ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\"\"\"\n",
    "    \n",
    "    print(\"=== ãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===\\n\")\n",
    "    \n",
    "    print(\"ã€æ­£å¸¸ãªå‡¦ç†é †åºã€‘\")\n",
    "    print(\"æ™‚åˆ»1: ãƒ—ãƒ­ã‚»ã‚¹A - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {}\")\n",
    "    print(\"æ™‚åˆ»2: ãƒ—ãƒ­ã‚»ã‚¹A - image1ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\")\n",
    "    print(\"æ™‚åˆ»3: ãƒ—ãƒ­ã‚»ã‚¹A - JSONã«{'image1': data1}è¿½åŠ ä¿å­˜\")\n",
    "    print(\"æ™‚åˆ»4: ãƒ—ãƒ­ã‚»ã‚¹B - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {'image1': data1}\")\n",
    "    print(\"æ™‚åˆ»5: ãƒ—ãƒ­ã‚»ã‚¹B - image2ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\")\n",
    "    print(\"æ™‚åˆ»6: ãƒ—ãƒ­ã‚»ã‚¹B - JSONã«{'image1': data1, 'image2': data2}ä¿å­˜\\n\")\n",
    "    \n",
    "    print(\"ã€å•é¡Œã®ã‚ã‚‹å‡¦ç†é †åºï¼ˆãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ï¼‰ã€‘\")\n",
    "    print(\"æ™‚åˆ»1: ãƒ—ãƒ­ã‚»ã‚¹A - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {}\")\n",
    "    print(\"æ™‚åˆ»2: ãƒ—ãƒ­ã‚»ã‚¹B - JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ {} (åŒã˜ç©ºãƒ‡ãƒ¼ã‚¿)\")\n",
    "    print(\"æ™‚åˆ»3: ãƒ—ãƒ­ã‚»ã‚¹A - image1ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\")\n",
    "    print(\"æ™‚åˆ»4: ãƒ—ãƒ­ã‚»ã‚¹B - image2ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†\")\n",
    "    print(\"æ™‚åˆ»5: ãƒ—ãƒ­ã‚»ã‚¹A - JSONã«{'image1': data1}ä¿å­˜\")\n",
    "    print(\"æ™‚åˆ»6: ãƒ—ãƒ­ã‚»ã‚¹B - JSONã«{'image2': data2}ä¿å­˜ â† image1ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆå¤±!\")\n",
    "    print(\"æ™‚åˆ»7: ã¾ãŸã¯ã€ãƒ—ãƒ­ã‚»ã‚¹BãŒimage1ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’image2ã«èª¤ã£ã¦çµåˆ\\n\")\n",
    "    \n",
    "    print(\"ã€çµæœã€‘\")\n",
    "    print(\"- image1ã®ç”»åƒã«ã€image2ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒçµã³ä»˜ã\")\n",
    "    print(\"- ã¾ãŸã¯ã€image1ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œå…¨ã«å¤±ã‚ã‚Œã‚‹\")\n",
    "    print(\"- JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯image2ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿æ®‹ã‚‹\\n\")\n",
    "\n",
    "def recommend_solutions():\n",
    "    \"\"\"è§£æ±ºç­–ã®ææ¡ˆ\"\"\"\n",
    "    \n",
    "    print(\"=== è§£æ±ºç­–ã®ææ¡ˆ ===\\n\")\n",
    "    \n",
    "    print(\"ğŸ”§ ã€ç·Šæ€¥å¯¾ç­–ã€‘\")\n",
    "    print(\"1. ä¸¦è¡Œå‡¦ç†ã‚’ç„¡åŠ¹åŒ–\")\n",
    "    print(\"   - max_workers=1 ã«è¨­å®š\")\n",
    "    print(\"   - ã¾ãŸã¯ ProcessPoolExecutor ã‚’ä½¿ã‚ãšé †æ¬¡å‡¦ç†\\n\")\n",
    "    \n",
    "    print(\"2. ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯ã®å®Ÿè£…\")\n",
    "    print(\"\"\"\n",
    "    from multiprocessing import Manager\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        with Manager() as manager:\n",
    "            file_lock = manager.Lock()  # ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯\n",
    "            with ProcessPoolExecutor(max_workers=20) as executor:\n",
    "                futures = []\n",
    "                for file_path in file_path_list:\n",
    "                    futures.append(executor.submit(\n",
    "                        main_exe_for_one_image,\n",
    "                        file_path=file_path,\n",
    "                        json_gt=json_gt,\n",
    "                        file_lock=file_lock  # ãƒ­ãƒƒã‚¯ã‚’æ¸¡ã™\n",
    "                    ))\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"3. å€‹åˆ¥JSONãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼\")\n",
    "    print(\"   - å„ç”»åƒã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\")\n",
    "    print(\"   - æœ€å¾Œã«å…¨ã¦ã‚’çµ±åˆ\")\n",
    "    print(\"   - ä¾‹: image1.json, image2.json â†’ æœ€çµ‚çš„ã«çµ±åˆ\\n\")\n",
    "    \n",
    "    print(\"ğŸ”§ ã€æ ¹æœ¬çš„è§£æ±ºç­–ã€‘\")\n",
    "    print(\"1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½¿ç”¨ (SQLite)\")\n",
    "    print(\"2. ã‚­ãƒ¥ãƒ¼æ–¹å¼ã§ã®é †æ¬¡æ›¸ãè¾¼ã¿\")\n",
    "    print(\"3. äº‹å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«IDãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯\\n\")\n",
    "\n",
    "# åˆ†æå®Ÿè¡Œ\n",
    "analyze_concurrent_processing_risks()\n",
    "simulate_race_condition()\n",
    "recommend_solutions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4aa193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç·Šæ€¥å¯¾ç­–: generate_dateset.py ã®ä¿®æ­£ ===\n",
      "\n",
      "ğŸš¨ ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ (å•é¡Œã‚ã‚Š):\n",
      "\n",
      "    if __name__ == \"__main__\":\n",
      "        with Manager() as manager:\n",
      "            with ProcessPoolExecutor(max_workers=20) as executor:  # â† 20ä¸¦åˆ—\n",
      "                for doc_path in doc_path_list:\n",
      "                    for file_path in file_path_list:\n",
      "                        if procedure_for_one_image != None:\n",
      "                            futures.append(executor.submit(\n",
      "                                main_exe_for_one_image, \n",
      "                                file_path=file_path,\n",
      "                                json_gt=json_gt,\n",
      "                                procedure_for_one_image=procedure_for_one_image\n",
      "                            ))\n",
      "    \n",
      "âœ… ä¿®æ­£ç‰ˆ1: ä¸¦è¡Œå‡¦ç†ç„¡åŠ¹åŒ–\n",
      "\n",
      "    if __name__ == \"__main__\":\n",
      "        with Manager() as manager:\n",
      "            with ProcessPoolExecutor(max_workers=1) as executor:  # â† 1ã«å¤‰æ›´\n",
      "                for doc_path in doc_path_list:\n",
      "                    for file_path in file_path_list:\n",
      "                        if procedure_for_one_image != None:\n",
      "                            futures.append(executor.submit(\n",
      "                                main_exe_for_one_image, \n",
      "                                file_path=file_path,\n",
      "                                json_gt=json_gt,\n",
      "                                procedure_for_one_image=procedure_for_one_image\n",
      "                            ))\n",
      "    \n",
      "âœ… ä¿®æ­£ç‰ˆ2: å®Œå…¨ã«é †æ¬¡å‡¦ç†\n",
      "\n",
      "    if __name__ == \"__main__\":\n",
      "        for doc_path in doc_path_list:\n",
      "            for file_path in file_path_list:\n",
      "                if procedure_for_one_image != None:\n",
      "                    # ç›´æ¥å®Ÿè¡Œï¼ˆä¸¦è¡Œå‡¦ç†ãªã—ï¼‰\n",
      "                    main_exe_for_one_image(\n",
      "                        file_path=file_path,\n",
      "                        json_gt=json_gt,\n",
      "                        procedure_for_one_image=procedure_for_one_image\n",
      "                    )\n",
      "    \n",
      "âš ï¸ æ³¨æ„ç‚¹:\n",
      "- å‡¦ç†æ™‚é–“ã¯20å€é•·ããªã‚Šã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãŒä¿ãŸã‚Œã¾ã™\n",
      "- æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–ã£ã¦ã‹ã‚‰å†ç”Ÿæˆã—ã¦ãã ã•ã„\n",
      "- é•·æœŸçš„ã«ã¯ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯ã¾ãŸã¯å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ã¸ã®ç§»è¡Œã‚’æ¨å¥¨\n",
      "\n",
      "ğŸ”§ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ‰‹é †:\n",
      "1. ç¾åœ¨ã®gt_json.jsonã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n",
      "2. generate_dateset.pyã‚’ä¿®æ­£ç‰ˆã§å®Ÿè¡Œ\n",
      "3. çµæœã‚’ç¢ºèªã—ã¦å•é¡ŒãŒãªã„ã“ã¨ã‚’æ¤œè¨¼\n"
     ]
    }
   ],
   "source": [
    "def emergency_fix_suggestion():\n",
    "    \"\"\"ç·Šæ€¥å¯¾ç­–ã®å…·ä½“çš„ãªä¿®æ­£ææ¡ˆ\"\"\"\n",
    "    \n",
    "    print(\"=== ç·Šæ€¥å¯¾ç­–: generate_dateset.py ã®ä¿®æ­£ ===\\n\")\n",
    "    \n",
    "    print(\"ğŸš¨ ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ (å•é¡Œã‚ã‚Š):\")\n",
    "    print(\"\"\"\n",
    "    if __name__ == \"__main__\":\n",
    "        with Manager() as manager:\n",
    "            with ProcessPoolExecutor(max_workers=20) as executor:  # â† 20ä¸¦åˆ—\n",
    "                for doc_path in doc_path_list:\n",
    "                    for file_path in file_path_list:\n",
    "                        if procedure_for_one_image != None:\n",
    "                            futures.append(executor.submit(\n",
    "                                main_exe_for_one_image, \n",
    "                                file_path=file_path,\n",
    "                                json_gt=json_gt,\n",
    "                                procedure_for_one_image=procedure_for_one_image\n",
    "                            ))\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"âœ… ä¿®æ­£ç‰ˆ1: ä¸¦è¡Œå‡¦ç†ç„¡åŠ¹åŒ–\")\n",
    "    print(\"\"\"\n",
    "    if __name__ == \"__main__\":\n",
    "        with Manager() as manager:\n",
    "            with ProcessPoolExecutor(max_workers=1) as executor:  # â† 1ã«å¤‰æ›´\n",
    "                for doc_path in doc_path_list:\n",
    "                    for file_path in file_path_list:\n",
    "                        if procedure_for_one_image != None:\n",
    "                            futures.append(executor.submit(\n",
    "                                main_exe_for_one_image, \n",
    "                                file_path=file_path,\n",
    "                                json_gt=json_gt,\n",
    "                                procedure_for_one_image=procedure_for_one_image\n",
    "                            ))\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"âœ… ä¿®æ­£ç‰ˆ2: å®Œå…¨ã«é †æ¬¡å‡¦ç†\")\n",
    "    print(\"\"\"\n",
    "    if __name__ == \"__main__\":\n",
    "        for doc_path in doc_path_list:\n",
    "            for file_path in file_path_list:\n",
    "                if procedure_for_one_image != None:\n",
    "                    # ç›´æ¥å®Ÿè¡Œï¼ˆä¸¦è¡Œå‡¦ç†ãªã—ï¼‰\n",
    "                    main_exe_for_one_image(\n",
    "                        file_path=file_path,\n",
    "                        json_gt=json_gt,\n",
    "                        procedure_for_one_image=procedure_for_one_image\n",
    "                    )\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"âš ï¸ æ³¨æ„ç‚¹:\")\n",
    "    print(\"- å‡¦ç†æ™‚é–“ã¯20å€é•·ããªã‚Šã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãŒä¿ãŸã‚Œã¾ã™\")\n",
    "    print(\"- æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–ã£ã¦ã‹ã‚‰å†ç”Ÿæˆã—ã¦ãã ã•ã„\")\n",
    "    print(\"- é•·æœŸçš„ã«ã¯ãƒ—ãƒ­ã‚»ã‚¹é–“ãƒ­ãƒƒã‚¯ã¾ãŸã¯å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ã¸ã®ç§»è¡Œã‚’æ¨å¥¨\\n\")\n",
    "    \n",
    "    print(\"ğŸ”§ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ‰‹é †:\")\n",
    "    print(\"1. ç¾åœ¨ã®gt_json.jsonã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\")\n",
    "    print(\"2. generate_dateset.pyã‚’ä¿®æ­£ç‰ˆã§å®Ÿè¡Œ\") \n",
    "    print(\"3. çµæœã‚’ç¢ºèªã—ã¦å•é¡ŒãŒãªã„ã“ã¨ã‚’æ¤œè¨¼\")\n",
    "    \n",
    "emergency_fix_suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517df6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
